{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b47188",
   "metadata": {},
   "source": [
    "## Import libraries for data loading, modeling, and visualization\n",
    "We bring in PyTorch for building neural networks, torchvision for the MNIST dataset and image transforms, and matplotlib so we can visualize digits later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90027b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bbbf1",
   "metadata": {},
   "source": [
    "## Download the MNIST datasets and convert them to tensors\n",
    "MNIST is a collection of 28x28 grayscale images of handwritten digits (0â€“9). We download both the training and test splits and immediately convert each image into a PyTorch tensor so the model can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2036a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\", train=True, transform=ToTensor(), download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\", train=False, transform=ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af153e3e",
   "metadata": {},
   "source": [
    "## Double-check the tensor shape of the training set\n",
    "Inspecting the shape confirms how many training samples we have and ensures each image is 28x28 pixels with a single channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a424a6-7b8b-4e6f-a597-8153468a3236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7a344",
   "metadata": {},
   "source": [
    "## Verify the tensor shape of the test set\n",
    "The test set should mirror the same structure so evaluation uses data identical to the training format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03bb27e5-31a0-4a97-afad-d5c3e0c48706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c265e641",
   "metadata": {},
   "source": [
    "## Inspect the label tensor to confirm class coverage\n",
    "Viewing the labels helps verify that all digits are present and that labels align with the image tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe9a058-6e99-40f1-8455-e5ad96eb7aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a3aca",
   "metadata": {},
   "source": [
    "## Build PyTorch data loaders for training and evaluation\n",
    "DataLoaders handle shuffling, batching, and parallel loading, which keeps the training loop clean and efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28758450-a7b4-49c9-913c-4a242e08ce72",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    \"train\": DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "    \"test\": DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2eb0f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Define the convolutional neural network used for MNIST classification\n",
    "This class builds a small CNN: two convolutional layers capture image patterns, followed by fully connected layers that map the extracted features to digit predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe46dac-eb4f-43fb-a876-0863d0338470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f4eff",
   "metadata": {},
   "source": [
    "## Configure device, instantiate the model, and define optimizer, loss, and loops\n",
    "We move everything to GPU if available, create the CNN, choose the Adam optimizer to adjust weights, and set cross-entropy as the loss to measure prediction quality against labels. The `train` helper runs one pass through the shuffled training batches, while `test` switches the model to evaluation mode and measures accuracy on unseen data without updating weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c9e77a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "MODEL_STATE_PATH = Path(\"mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100.0 * batch_idx / len(loaders['train']):.0f}%)]\\t{loss.item():.6}\"\n",
    "            )\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "    print(\n",
    "        f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders['test'].dataset)} ({100.0 * correct / len(loaders['test'].dataset):.0f}%\\n)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2044f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Load existing weights or train for multiple epochs\n",
    "If a saved checkpoint exists we ask whether to reuse it; otherwise we loop through the dataset ten times, logging accuracy after each epoch before persisting the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19d9d3ef-a943-4d95-bb3a-5d128b140809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_training_flow(retrain: bool = True, epochs: int = 10):\n",
    "    should_retrain = retrain or not MODEL_STATE_PATH.exists()\n",
    "\n",
    "    if should_retrain:\n",
    "        print(f\"Model is currently being trained using {str(device).upper()}\")\n",
    "        time.sleep(1)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        torch.save(model.state_dict(), MODEL_STATE_PATH)\n",
    "        print(f\"Saved trained weights to {MODEL_STATE_PATH}\")\n",
    "    else:\n",
    "        _load_model_state()\n",
    "\n",
    "\n",
    "def _load_model_state():\n",
    "    if not MODEL_STATE_PATH.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"No trained weights found at {MODEL_STATE_PATH}. Run training first.\"\n",
    "        )\n",
    "    model.load_state_dict(torch.load(MODEL_STATE_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"Loaded trained weights from {MODEL_STATE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_test_index() -> int:\n",
    "    return len(test_data) - 1\n",
    "\n",
    "\n",
    "def _get_test_sample(sample_index: int):\n",
    "    clamped_index = max(0, min(sample_index, get_max_test_index()))\n",
    "    data, target = test_data[clamped_index]\n",
    "    return clamped_index, data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc3099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_sample(sample_index: int):\n",
    "    model.eval()\n",
    "\n",
    "    clamped_index, data, target = _get_test_sample(sample_index)\n",
    "\n",
    "    batch = data.unsqueeze(0).to(device)\n",
    "    output = model(batch)\n",
    "    prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "    return {\n",
    "        \"index\": clamped_index,\n",
    "        \"prediction\": prediction,\n",
    "        \"label\": int(target),\n",
    "        \"image\": data.squeeze(0).cpu().numpy(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc2b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62830296-433c-4af9-aa2d-d75cedfa7193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-uppgift01",
   "language": "python",
   "name": "python-uppgift01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
