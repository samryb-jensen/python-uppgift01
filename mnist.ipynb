{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b47188",
   "metadata": {},
   "source": [
    "## MNIST utilities\n",
    "Torch- and torchvision-based helpers for training, evaluating, and using the\n",
    "convolutional neural network that powers the MNIST CLI app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25ef6a",
   "metadata": {},
   "source": [
    "### Library imports\n",
    "Core PyTorch building blocks plus torchvision datasets/transforms used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90027b79",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1447adb1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### CNN backbone\n",
    "Feature extractor invoked by the higher-level `Model` wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc617d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f009bec",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "MODEL_STATE_PATH = Path(\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba354a2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### High-level model API\n",
    "Handles dataset setup, training loops, evaluation, checkpointing, and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2b8a8c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_path: Path | str = MODEL_STATE_PATH,\n",
    "        batch_size: int = 100,\n",
    "        data_root: str = \"data\",\n",
    "        download: bool = True,\n",
    "    ) -> None:\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.state_path = Path(state_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.data_root = data_root\n",
    "\n",
    "        transform = ToTensor()\n",
    "        self.train_data = datasets.MNIST(\n",
    "            root=data_root, train=True, transform=transform, download=download\n",
    "        )\n",
    "        self.test_data = datasets.MNIST(\n",
    "            root=data_root, train=False, transform=transform, download=download\n",
    "        )\n",
    "\n",
    "        self.loaders = {\n",
    "            \"train\": DataLoader(\n",
    "                self.train_data, batch_size=batch_size, shuffle=True, num_workers=1\n",
    "            ),\n",
    "            \"test\": DataLoader(\n",
    "                self.test_data, batch_size=batch_size, shuffle=True, num_workers=1\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        self.network = CNN().to(self.device)\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=0.001)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, state_path: Path | str = MODEL_STATE_PATH, **kwargs) -> \"Model\":\n",
    "        model = cls(state_path=state_path, download=False, **kwargs)\n",
    "        model.load_weights(state_path)\n",
    "        return model\n",
    "\n",
    "    def load_weights(self, state_path: Path | str | None = None) -> None:\n",
    "        path = Path(state_path) if state_path else self.state_path\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"No trained weights found at {path}. Run training first.\"\n",
    "            )\n",
    "        self.network.load_state_dict(torch.load(path, map_location=self.device))\n",
    "        self.network.to(self.device)\n",
    "        print(f\"Loaded trained weights from {path}\")\n",
    "\n",
    "    def save(self, state_path: Path | str | None = None) -> None:\n",
    "        path = Path(state_path) if state_path else self.state_path\n",
    "        torch.save(self.network.state_dict(), path)\n",
    "        print(f\"Saved trained weights to {path}\")\n",
    "\n",
    "    def train(self, epochs: int = 10, save: bool = True) -> None:\n",
    "        print(f\"Model is currently being trained using {str(self.device).upper()}\")\n",
    "        time.sleep(1)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self._train_single_epoch(epoch)\n",
    "            self.test()\n",
    "\n",
    "        if save:\n",
    "            self.save()\n",
    "\n",
    "    def _train_single_epoch(self, epoch: int) -> None:\n",
    "        self.network.train()\n",
    "        for batch_idx, (data, target) in enumerate(self.loaders[\"train\"]):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.network(data)\n",
    "            loss = self.loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % 20 == 0:\n",
    "                seen = batch_idx * len(data)\n",
    "                total = len(self.loaders[\"train\"].dataset)\n",
    "                pct = 100.0 * batch_idx / len(self.loaders[\"train\"])\n",
    "                print(\n",
    "                    f\"Train Epoch: {epoch} [{seen}/{total} ({pct:.0f}%)]\\t{loss.item():.6}\"\n",
    "                )\n",
    "\n",
    "    def test(self) -> dict[str, float | int]:\n",
    "        self.network.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = len(self.loaders[\"test\"].dataset)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.loaders[\"test\"]:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.network(data)\n",
    "                test_loss += self.loss_fn(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        avg_loss = test_loss / total\n",
    "        accuracy = 100.0 * correct / total\n",
    "        print(\n",
    "            f\"\\nTest set: Average loss: {avg_loss:.4f}, Accuracy {correct}/{total} ({accuracy:.0f}%)\\n\"\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": avg_loss,\n",
    "            \"correct\": correct,\n",
    "            \"total\": total,\n",
    "            \"accuracy\": accuracy,\n",
    "        }\n",
    "\n",
    "    def get_max_test_index(self) -> int:\n",
    "        return len(self.test_data) - 1\n",
    "\n",
    "    def _get_test_sample(self, sample_index: int):\n",
    "        clamped_index = max(0, min(sample_index, self.get_max_test_index()))\n",
    "        data, target = self.test_data[clamped_index]\n",
    "        return clamped_index, data, target\n",
    "\n",
    "    def classify(self, sample_index: int) -> dict[str, object]:\n",
    "        self.network.eval()\n",
    "        clamped_index, data, target = self._get_test_sample(sample_index)\n",
    "        batch = data.unsqueeze(0).to(self.device)\n",
    "        output = self.network(batch)\n",
    "        prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "        return {\n",
    "            \"index\": clamped_index,\n",
    "            \"prediction\": prediction,\n",
    "            \"label\": int(target),\n",
    "            \"image\": data.squeeze(0).cpu().numpy(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723fd62-a836-44f7-8966-1f30bac659c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-uppgift01",
   "language": "python",
   "name": "python-uppgift01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
